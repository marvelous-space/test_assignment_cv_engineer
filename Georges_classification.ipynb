{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/olga/test_assignment_cv_engineer_data\n",
      "/Users/olga/test_assignment_cv_engineer_data/dataset\n",
      "/Users/olga/test_assignment_cv_engineer_data/dataset\n",
      "/Users/olga/test_assignment_cv_engineer_data/dataset\n",
      "/Users/olga/test_assignment_cv_engineer_data/dataset\n",
      "/Users/olga/test_assignment_cv_engineer_data/dataset\n",
      "/Users/olga/test_assignment_cv_engineer_data/dataset/train\n",
      "/Users/olga/test_assignment_cv_engineer_data/dataset/train\n",
      "/Users/olga/test_assignment_cv_engineer_data/dataset/test\n",
      "/Users/olga/test_assignment_cv_engineer_data/dataset/test\n",
      "/Users/olga/test_assignment_cv_engineer_data/dataset/validation\n",
      "/Users/olga/test_assignment_cv_engineer_data/dataset/validation\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def create_dir(dir, new):\n",
    "    path = dir/ new\n",
    "    path.mkdir(exist_ok=True)\n",
    "    print(dir)\n",
    "    return path\n",
    "\n",
    "base_dir = create_dir(Path.cwd(), 'dataset')\n",
    "train_dir = create_dir(base_dir, 'train')\n",
    "test_dir = create_dir(base_dir, 'test')\n",
    "valid_dir = create_dir(base_dir, 'validation')\n",
    "georges_help_dir = create_dir(base_dir, 'georges_help')\n",
    "non_georges_help_dir = create_dir(base_dir, 'non_georges_help')\n",
    "\n",
    "train_georges_dir = create_dir(train_dir, 'georges')\n",
    "train_non_georges_dir = create_dir(train_dir, 'non_georges')\n",
    "test_georges_dir = create_dir(test_dir, 'georges')\n",
    "test_non_georges_dir = create_dir(test_dir, 'non_georges')\n",
    "valid_georges_dir = create_dir(valid_dir, 'georges')\n",
    "valid_non_georges_dir = create_dir(valid_dir, 'non_georges')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачиваю файлы с ссылками картинки с гугл диск"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://docs.google.com/uc?export=download&id=1RzK75yN2Fywrty3GoIfSajbfsgZULoQ5\" -O georges.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://docs.google.com/uc?export=download&id=1nyfSC465u-W-DUeIKh8m5U44Z0SS2tyk\" -O non_georges.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортирую скаачнные таблицы в txt файлы с соответствующими именами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('georges.csv')\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.to_csv(\"georges.txt\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('non_georges.csv')\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.to_csv(\"non_georges.txt\", header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "скачиваю картинки по ссылкам в txt файле в папку georges_help и последовательно переименовываю их в формат georges_1.jpg и \n",
    "non_georges_1.jpg, чтобы потом переложить в соответствующие папки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P ./dataset/georges_help/ --random-wait -i georges.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -P ./dataset/non_georges_help/ --random-wait -i non_georges.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "i = 0\n",
    "for path in pathlib.Path(\"dataset/georges_help\").iterdir():\n",
    "    if path.is_file():\n",
    "        #old_name = path.stem\n",
    "#исходное имя файла\n",
    "        old_extension = path.suffix\n",
    "#исходное расширение файла\n",
    "        directory = path.parent\n",
    "#текущее расположение файла\n",
    "\n",
    "        new_name = \"georges\" + str(i) + old_extension\n",
    "        i += 1\n",
    "\n",
    "        path.rename(pathlib.Path(directory, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "i = 0\n",
    "for path in pathlib.Path(\"dataset/non_georges_help\").iterdir():\n",
    "    if path.is_file():\n",
    "        #old_name = path.stem\n",
    "#исходное имя файла\n",
    "        old_extension = path.suffix\n",
    "#исходное расширение файла\n",
    "        directory = path.parent\n",
    "#текущее расположение файла\n",
    "\n",
    "        new_name = \"non_georges\" + str(i) + old_extension\n",
    "        i += 1\n",
    "\n",
    "        path.rename(pathlib.Path(directory, new_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перекладываю картинки из папки non_georges_help в папку georges_help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "def copy_files(src, dest, name, start, stop):\n",
    "    fnames = [f'{name}{i}.jpg' for i in range(start,stop)]\n",
    "    for fname in fnames:\n",
    "        src_file = src / fname\n",
    "        dest_file = dest / fname\n",
    "        shutil.copy(src_file, dest_file)\n",
    "\n",
    "src = Path.cwd() /'dataset'/ 'non_georges_help'\n",
    "\n",
    "copy_files(src, georges_help, 'non_georges', 0, 3338)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Перекладываю картинки georges и non_georges по папкам train, test, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "def copy_files(src, dest, name, start, stop):\n",
    "    fnames = [f'{name}{i}.jpg' for i in range(start,stop)]\n",
    "    for fname in fnames:\n",
    "        src_file = src / fname\n",
    "        dest_file = dest / fname\n",
    "        shutil.copy(src_file, dest_file)\n",
    "\n",
    "src = Path.cwd() /'dataset'/ 'georges_help'\n",
    "#train_georges_dir = Path.cwd() /'dataset'/'train'/'georges'\n",
    "\n",
    "copy_files(src, train_georges_dir, 'georges', 0, 1100)\n",
    "copy_files(src, train_non_georges_dir, 'non_georges', 0, 1670)\n",
    "copy_files(src, test_georges_dir, 'georges', 1100, 1700)\n",
    "copy_files(src, test_non_georges_dir, 'non_georges', 1670, 2500)\n",
    "copy_files(src, valid_georges_dir, 'georges', 1700, 2300)\n",
    "copy_files(src, valid_non_georges_dir, 'non_georges', 2500, 3330)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Извлекаю архитектуру VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "conv_base = VGG16(weights='imagenet', # Источник весов\n",
    "                  include_top=False, # Не подключать полносвязный слой\n",
    "                  input_shape=(150, 150, 3)) # Форма входных тензоров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Извлекаю признаки, выдаваемые сверточной основой архитектуры VGG16. Я указываю, что выходной признак должен иметь форму (образцы,4,4,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "def extract_features(directory, sample_count, batch_size=20):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "    for i, (inputs_batch, labels_batch) in enumerate(generator):\n",
    "        if i * batch_size >= sample_count:\n",
    "            # Генераторы могут находится в цикле до бесконечности,\n",
    "            # поэтому нужно прервать после передачи всех изображений\n",
    "            break\n",
    "        # Предказываем на основе сверточной основы VGG16:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Для каждого набора изображений вызывается conv_base.predict для получения результата от сверточной основы. \n",
    "Этот результат я сохраняю в features и вызваю этот метод применительно к папкам с картинками:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2770 images belonging to 2 classes.\n",
      "Found 1430 images belonging to 2 classes.\n",
      "Found 1430 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = extract_features(train_dir, 2770)\n",
    "valid_features, valid_labels = extract_features(valid_dir, 1430)\n",
    "test_features, test_labels = extract_features(test_dir, 1430)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.reshape(train_features, (2770, 4 * 4 * 512))\n",
    "valid_features = np.reshape(valid_features, (1430, 4 * 4 * 512))\n",
    "test_features = np.reshape(test_features, (1430, 4 * 4 * 512))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полносвязный классификатор, который имеет на входе 256 нейронов и 1 на выходе. Ещё я добавила слой Dropout, чтобы избежать переобучения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "139/139 [==============================] - 3s 17ms/step - loss: 0.6659 - acc: 0.6077 - val_loss: 0.5265 - val_acc: 0.7469\n",
      "Epoch 2/30\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 0.5308 - acc: 0.7381 - val_loss: 0.4843 - val_acc: 0.7706\n",
      "Epoch 3/30\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 0.4750 - acc: 0.7830 - val_loss: 0.4567 - val_acc: 0.7958\n",
      "Epoch 4/30\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 0.4592 - acc: 0.7741 - val_loss: 0.4436 - val_acc: 0.8007\n",
      "Epoch 5/30\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 0.3955 - acc: 0.8276 - val_loss: 0.4383 - val_acc: 0.8042\n",
      "Epoch 6/30\n",
      "139/139 [==============================] - 2s 13ms/step - loss: 0.4085 - acc: 0.8232 - val_loss: 0.4406 - val_acc: 0.8042\n",
      "Epoch 7/30\n",
      "139/139 [==============================] - 2s 13ms/step - loss: 0.4051 - acc: 0.8204 - val_loss: 0.4377 - val_acc: 0.8077\n",
      "Epoch 8/30\n",
      "139/139 [==============================] - 2s 13ms/step - loss: 0.3700 - acc: 0.8404 - val_loss: 0.4135 - val_acc: 0.8259\n",
      "Epoch 9/30\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 0.3611 - acc: 0.8332 - val_loss: 0.4040 - val_acc: 0.8301\n",
      "Epoch 10/30\n",
      "139/139 [==============================] - 2s 14ms/step - loss: 0.3453 - acc: 0.8601 - val_loss: 0.4000 - val_acc: 0.8336\n",
      "Epoch 11/30\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 0.3265 - acc: 0.8657 - val_loss: 0.3954 - val_acc: 0.8413\n",
      "Epoch 12/30\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 0.3263 - acc: 0.8761 - val_loss: 0.3923 - val_acc: 0.8308\n",
      "Epoch 13/30\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 0.3124 - acc: 0.8808 - val_loss: 0.3963 - val_acc: 0.8322\n",
      "Epoch 14/30\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 0.2917 - acc: 0.8944 - val_loss: 0.3903 - val_acc: 0.8378\n",
      "Epoch 15/30\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 0.2916 - acc: 0.8944 - val_loss: 0.4065 - val_acc: 0.8231\n",
      "Epoch 16/30\n",
      "139/139 [==============================] - 2s 13ms/step - loss: 0.2992 - acc: 0.8805 - val_loss: 0.3817 - val_acc: 0.8448\n",
      "Epoch 17/30\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 0.2732 - acc: 0.8897 - val_loss: 0.3806 - val_acc: 0.8455\n",
      "Epoch 18/30\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 0.2578 - acc: 0.8957 - val_loss: 0.3843 - val_acc: 0.8406\n",
      "Epoch 19/30\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 0.2480 - acc: 0.9086 - val_loss: 0.3782 - val_acc: 0.8455\n",
      "Epoch 20/30\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 0.2656 - acc: 0.9002 - val_loss: 0.3692 - val_acc: 0.8573\n",
      "Epoch 21/30\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 0.2451 - acc: 0.9016 - val_loss: 0.3719 - val_acc: 0.8524\n",
      "Epoch 22/30\n",
      "139/139 [==============================] - 2s 13ms/step - loss: 0.2496 - acc: 0.9038 - val_loss: 0.3719 - val_acc: 0.8517\n",
      "Epoch 23/30\n",
      "139/139 [==============================] - 2s 16ms/step - loss: 0.2262 - acc: 0.9184 - val_loss: 0.3676 - val_acc: 0.8594\n",
      "Epoch 24/30\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 0.2231 - acc: 0.9201 - val_loss: 0.3669 - val_acc: 0.8559\n",
      "Epoch 25/30\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 0.2372 - acc: 0.9206 - val_loss: 0.3668 - val_acc: 0.8566\n",
      "Epoch 26/30\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 0.2307 - acc: 0.9137 - val_loss: 0.3658 - val_acc: 0.8573\n",
      "Epoch 27/30\n",
      "139/139 [==============================] - 2s 13ms/step - loss: 0.1990 - acc: 0.9377 - val_loss: 0.3661 - val_acc: 0.8615\n",
      "Epoch 28/30\n",
      "139/139 [==============================] - 2s 12ms/step - loss: 0.2011 - acc: 0.9299 - val_loss: 0.3784 - val_acc: 0.8503\n",
      "Epoch 29/30\n",
      "139/139 [==============================] - 2s 13ms/step - loss: 0.1944 - acc: 0.9366 - val_loss: 0.3850 - val_acc: 0.8503\n",
      "Epoch 30/30\n",
      "139/139 [==============================] - 2s 13ms/step - loss: 0.2010 - acc: 0.9290 - val_loss: 0.3710 - val_acc: 0.8608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9e250c8090>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import (\n",
    "    models, layers, optimizers)\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from datetime import datetime\n",
    "model = models.Sequential([\n",
    "    layers.Dense(256, activation='relu', input_dim=4 * 4 * 512),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "log_dir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "model.fit(train_features, train_labels,\n",
    "          epochs=30,\n",
    "          batch_size=20,\n",
    "          validation_data=(valid_features, valid_labels),\n",
    "          callbacks=[tensorboard_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
